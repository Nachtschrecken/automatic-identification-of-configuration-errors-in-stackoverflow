{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis using ChatGPT\n",
    "#### Analyzing posts containing configuration errors on various attributes\n",
    "\n",
    "In this notebook, we use the LLM ChatGPT (chatgpt3.5-turbo) to analyze a set of posts containing configuration errors on different aspects like the tech stack, cause of the configuration error, or impact of the configuration error. For this purpose we will use the 'true'-labeled documents from our manually selected dataset as well as some false positives by the best performing prompting method from the second approach of the first experiment. This will help us to better understand why the false positives resulted at and what we can learn from that.\n",
    "\n",
    "2023, Ferris Kleier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of libraries and secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import secret\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "API_KEY = secret.get_apikey()\n",
    "URL = secret.get_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function definitions for this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(time, role, outputs, tokens):\n",
    "    log_string = '\\nDate: ' + time + '\\nRole: ' + role + '\\n\\nOutputs: \\n\\n'\n",
    "    for output in outputs:\n",
    "        log_string = log_string + 'Input: #' + str(output[0]) + ', ' + output[1] + '\\nOutput:\\n' + output[2] + '\\n\\n'\n",
    "    log_string = log_string + '\\n' + 'Tokens: ' + str(tokens)\n",
    "\n",
    "    with open(\"../Code/analysis_log.txt\", \"a\") as f:\n",
    "        f.write(\"\\n\\n--------------------------------\")\n",
    "        f.write(log_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def microlog(output, tokens):\n",
    "    log_string = '\\n\\nInput: #' + str(output[0]) + ', ' + output[1] + '\\nOutput:\\n' + output[2] + '\\n'\n",
    "    log_string = log_string + '\\n' + 'Tokens: ' + str(tokens)\n",
    "\n",
    "    with open(\"../Code/analysis_log.txt\", \"a\") as f:\n",
    "        f.write(log_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(role, input):\n",
    "    response = requests.post(URL, headers={'Authorization': API_KEY}, json={\n",
    "        'messages': [\n",
    "            {'role': 'system', 'content': role},\n",
    "            {'role': 'user', 'content': input}\n",
    "        ], \n",
    "        'temperature': 0,\n",
    "    })\n",
    "    \n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304133\n",
      "297\n"
     ]
    }
   ],
   "source": [
    "with open(\"../Code/old/output.txt\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    sum_of_numbers = 0\n",
    "    i = 0\n",
    "    for line in lines:\n",
    "        if line.startswith(\"Tokens: \"):\n",
    "            i = i + 1\n",
    "            result_string = line[len(\"Tokens: \"):]\n",
    "            number = int(result_string.strip())\n",
    "            sum_of_numbers += number\n",
    "    print(sum_of_numbers)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset creation\n",
    "\n",
    "Splitting the dataset to only contain the true labeled posts and posts that resulted in false positives by the Few-Shot-Prompting model. We are using the output of the best performing Few-Shot-Prompting model according to it's measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split():\n",
    "    false_positives = [\"329\",\"332\",\"335\",\"339\",\"350\",\"351\",\"356\",\"363\",\"369\",\"371\",\"379\",\"383\",\"385\",\"393\",\"397\",\"411\",\"416\",\"417\",\"418\",\"426\",\"431\",\"434\",\"435\",\"439\",\"441\",\"442\",\"444\",\"448\",\"460\",\"462\",\"476\",\"481\",\"493\",\"499\",\"500\",\"501\"]\n",
    "    with open(\"../Posts/dataset.xml\", encoding=\"utf-8-sig\") as xml_file:\n",
    "        dataset = ET.parse(xml_file)\n",
    "        root = dataset.getroot()\n",
    "        elements = root.findall(\"post\")\n",
    "\n",
    "        posts = []\n",
    "        for element in elements:\n",
    "            if element.get(\"label\") == \"True\":\n",
    "                posts.append([element.get(\"id\"),\"True Label\",element.get(\"text\")])\n",
    "            if element.get(\"id\") in false_positives:\n",
    "                posts.append([element.get(\"id\"),\"False Positive\",element.get(\"text\")])\n",
    "\n",
    "    return posts\n",
    "\n",
    "posts = split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents Analysis\n",
    "\n",
    "In this part, we use the API to analyze the dataset of true labeled posts. We constructed this prompt to include all aspects of the configuration error we want to be covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"You are given a post from Stack Overflow that contains talk about configuration errors. Analyze the post and it's configuration error \\\n",
    "          according to the following points: \\\n",
    "            1. Tech stack used: What information can be found in the post on the technology used? For example the programming language, frameworks, \\\n",
    "              or databases, is containerization used, is there information on the operating system, version control tools, or network? \\\n",
    "            2. Type of configuration error: What type of configuration error is the post about? Is it a missing configuration parameter, an invalid \\\n",
    "              configuration value, or a conflict between two configuration settings? \\\n",
    "            3. Cause of the configuration error: What caused the configuration error? Was it a typo, a misunderstanding of the configuration \\\n",
    "              documentation, or a bug in the software? \\\n",
    "            4. Impact of the configuration error: What impact did the configuration error have on the software? Did it cause the software to crash, \\\n",
    "              to behave incorrectly, or to produce unexpected results? \\\n",
    "            5. How to fix the configuration error: How can the configuration error be fixed? What tips would you suggest to the user to solve the \\\n",
    "              problem? Keep it short and simple.\"\n",
    "\n",
    "time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "tokens = 0\n",
    "outputs = []\n",
    "\n",
    "for post in posts[220:]:\n",
    "    output = prompt(role, post[2])\n",
    "    print([post[0],post[1],output['choices'][0]['message']['content']])\n",
    "    outputs.append([post[0],post[1],output['choices'][0]['message']['content']])\n",
    "    print(output['usage']['total_tokens'])\n",
    "    tokens = tokens + output['usage']['total_tokens']\n",
    "    microlog([post[0],post[1],output['choices'][0]['message']['content']],output['usage']['total_tokens'])\n",
    "\n",
    "# logging(time,role,outputs,tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
