{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CM-PaCE (Classifier Model for Posts about Configuration Errors)\n",
    "#### Implementation of Word2Vec feature extraction and SVM classification\n",
    "Using gensim for Word2Vec part\\\n",
    "Using sklearn for SVM part\n",
    "\n",
    "2023, Ferris Kleier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.parsing.preprocessing import *\n",
    "import sklearn.svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some defined constants to resuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, strip_punctuation,\n",
    "                  remove_stopwords, strip_multiple_whitespaces, strip_numeric, stem_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for the Word2Vec section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labeled_sets() processes the two full body sets of positive and negative posts and returns the combined full set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeled_sets():\n",
    "\n",
    "    full_set = []\n",
    "\n",
    "    with open(\"../Posts/positives_body.txt\", 'r') as f:\n",
    "        for line in f:\n",
    "            line = preprocess_string(line, CUSTOM_FILTERS)\n",
    "            full_set.append([line, True])\n",
    "\n",
    "    with open(\"../Posts/negatives_body.txt\", 'r') as f:\n",
    "        for line in f:\n",
    "            line = preprocess_string(line, CUSTOM_FILTERS)\n",
    "            full_set.append([line, False])\n",
    "            \n",
    "    return full_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logging(string) logs the output of the model with results and more into a seperate log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(string):\n",
    "    with open(\"../Code/cmpace_log.txt\", \"a\") as f:\n",
    "        f.write(\"\\n\\n--------------------------------\")\n",
    "        f.write(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return only the body dimension if a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bodies(set): \n",
    "    return [row[0] for row in set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Section\n",
    "In this section, we will implement the code for our Word2Vec model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the already defined function labeled_sets() to create a labeled, combined set of the raw bodies. This full set will then be split into the training and test set in a 90/10 ratio using the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(labeled_sets(), test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the sklearn method train_test_split() actually shuffles and slices the sets into the desired output. That way, the content is mixed and bias can be eliminated by purposefully shuffling the labels from both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235 216\n",
      "26 25\n"
     ]
    }
   ],
   "source": [
    "true_count_train, false_count_train = (\n",
    "    [row[1] for row in train_set].count(True),\n",
    "    [row[1] for row in train_set].count(False),\n",
    ")\n",
    "\n",
    "true_count_test, false_count_test = (\n",
    "    [row[1] for row in test_set].count(True),\n",
    "    [row[1] for row in test_set].count(False),\n",
    ")\n",
    "\n",
    "print(true_count_train, false_count_train)\n",
    "print(true_count_test, false_count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Selection\n",
    "\n",
    "**min_count**: this value defines the minimum occurrence of a word to be considered (suggest: 5)\\\n",
    "**alpha**: the initial learning rate of the model (suggest: 0.01)\\\n",
    "**epochs**: how many iterations the model performs (suggest: 500)\\\n",
    "**sg**: since we use the skip-gram approach, this indicates that it will be used for the model\\\n",
    "**hs**: if 1, hierarchical softmax will be used for model training\\\n",
    "**window**: the window size for which the skip-gram approach considers neighboring words\n",
    "\n",
    "Below you can see our current best values for producing the desired model, after evaluating and comparing several other parameter selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 5\n",
    "alpha = 0.01\n",
    "epochs = 500\n",
    "sg = 1\n",
    "hs = 1\n",
    "window = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation\n",
    "\n",
    "Creating the name for the model to be saved by time, for better evaluation. We also make use of a lambda function to just take the bodies of the training set, since Word2Vec makes no use of the provided labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "modelName = \"../Models/Word2Vec/cmpace_w2v_{time}.model\".format(time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the gensim library, we can create our model by just parsing the parameters. We also activate loss computation for further evaluation. The model will then be saved with the provided model name. This way we can compare different models and store every artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=get_bodies(train_set), min_count=min_count,\n",
    "                 sg=sg, hs=hs, window=window,\n",
    "                 alpha=alpha, epochs=epochs, compute_loss=True)\n",
    "\n",
    "model.save(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this block only if a model should be loaded from a provided path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"../Models/Word2Vec/cmpace_w2v_v2.1_PRIME.model\"\n",
    "model = gensim.models.Word2Vec.load(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the header information for our model, this will also be used to log the output of the model in the log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logString = f\"\\nParameters and Results for Word2Vec Model {modelName}\\n\" + \\\n",
    "    f\"min_count = {model.min_count}\\n\" + \\\n",
    "    f\"alpha = {model.alpha}\\n\" + \\\n",
    "    f\"sg = {model.sg}\\n\" + \\\n",
    "    f\"hs = {model.hs}\\n\" + \\\n",
    "    f\"window = {model.window}\\n\" + \\\n",
    "    f\"epochs = {model.epochs}\"\n",
    "lossString = f\"\\nloss = {model.get_latest_training_loss()}\\n\"\n",
    "logString += lossString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wv will be used as the primary function of the model for finding similar words or similarity between words. The word_vectors are the stored vectors of all words with their according relevance to all other words and serve as a full representation of the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = model.wv\n",
    "word_vectors = wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation\n",
    "\n",
    "In this section the model will be inspected to see if the values make sense. This uncovers overfitting for similarities above 0.999 or other indicators for the need of refined parameters like window size from the top n similar words.\n",
    "\n",
    "Here you can see the top n words by relevance in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 11: break\n",
    "    indexString = f\"{index}/{len(wv.index_to_key)}: {word}\"\n",
    "    logString += f\"\\n{indexString}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is the most interesting because we can see our model in action.\n",
    "\n",
    "We can inspect the similarity between words, the top n similar words to a provided word, or which words does not fit by context in a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity between config and error:\n",
      "0.294527530670166\n",
      "\n",
      "Most similar words for config:\n",
      "[('web', 0.5596780776977539), ('file', 0.5173095464706421), ('cudpp', 0.40932998061180115), ('rb', 0.40153074264526367), ('wwwroot', 0.3935110569000244)]\n",
      "\n",
      "Similarity between configur and error:\n",
      "0.7645865678787231\n",
      "\n",
      "Most similar words for configur:\n",
      "[('error', 0.7645866870880127), ('file', 0.5191519856452942), ('occur', 0.4893133342266083), ('give', 0.4655228853225708), ('applic', 0.42140066623687744)]\n",
      "\n",
      "Which does not fit in ['configur', 'error', 'invalid', 'java', 'problem', 'cloud']:\n",
      "java\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w1 = 'config'\n",
    "w2 = 'error'\n",
    "w3 = 'configur'\n",
    "wList = ['configur', 'error', 'invalid', 'java', 'problem', 'cloud']\n",
    "\n",
    "resString = (\n",
    "    f\"\\nSimilarity between {w1} and {w2}:\\n{wv.similarity(w1, w2)}\\n\\n\"\n",
    "    + f\"Most similar words for {w1}:\\n{wv.most_similar(positive=[w1], topn=5)}\\n\\n\"\n",
    "    + f\"Similarity between {w3} and {w2}:\\n{wv.similarity(w3, w2)}\\n\\n\"\n",
    "    + f\"Most similar words for {w3}:\\n{wv.most_similar(positive=[w3], topn=5)}\\n\\n\"\n",
    "    + f\"Which does not fit in {wList}:\\n{wv.doesnt_match(wList)}\\n\"\n",
    ")\n",
    "logString += f\"\\n{resString}\"\n",
    "\n",
    "print(resString)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the model and printing all outputs, the log will be written to keep track of all artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters and Results for Word2Vec Model ../Models/Word2Vec/cmpace_w2v_v2.1_PRIME.model\n",
      "min_count = 5\n",
      "alpha = 0.01\n",
      "sg = 1\n",
      "hs = 1\n",
      "window = 4\n",
      "epochs = 500\n",
      "loss = 57536732.0\n",
      "\n",
      "\n",
      "Similarity between config and error:\n",
      "0.294527530670166\n",
      "\n",
      "Most similar words for config:\n",
      "[('web', 0.5596780776977539), ('file', 0.5173095464706421), ('cudpp', 0.40932998061180115), ('rb', 0.40153074264526367), ('wwwroot', 0.3935110569000244)]\n",
      "\n",
      "Similarity between configur and error:\n",
      "0.7645865678787231\n",
      "\n",
      "Most similar words for configur:\n",
      "[('error', 0.7645866870880127), ('file', 0.5191519856452942), ('occur', 0.4893133342266083), ('give', 0.4655228853225708), ('applic', 0.42140066623687744)]\n",
      "\n",
      "Which does not fit in ['configur', 'error', 'invalid', 'java', 'problem', 'cloud']:\n",
      "java\n",
      "\n",
      "\n",
      "Similarity between config and error:\n",
      "0.294527530670166\n",
      "\n",
      "Most similar words for config:\n",
      "[('web', 0.5596780776977539), ('file', 0.5173095464706421), ('cudpp', 0.40932998061180115), ('rb', 0.40153074264526367), ('wwwroot', 0.3935110569000244)]\n",
      "\n",
      "Similarity between configur and error:\n",
      "0.7645865678787231\n",
      "\n",
      "Most similar words for configur:\n",
      "[('error', 0.7645866870880127), ('file', 0.5191519856452942), ('occur', 0.4893133342266083), ('give', 0.4655228853225708), ('applic', 0.42140066623687744)]\n",
      "\n",
      "Which does not fit in ['configur', 'error', 'invalid', 'java', 'problem', 'cloud']:\n",
      "java\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(logString)\n",
    "logging(logString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Section\n",
    "\n",
    "In this section we will build the SVM model that takes the feature vectors from the Word2Vec model and uses them as an input for the final classification model. The classification model will then be trained on the provided labels to learn the features of positive posts, resulting in a trained model that classifies a given post (any text) with either True or False.\n",
    "\n",
    "We first transform the necessary sets with feature vectors. Next, we train the model on the training set. And finally, the model will be evaluated on the test set with according measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions that are needed in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(set):\n",
    "    return [row[1] for row in set]\n",
    "\n",
    "\n",
    "def get_labels(set):\n",
    "    return [row[2] for row in set]\n",
    "\n",
    "\n",
    "def get_featurelength(set):\n",
    "    max = 0\n",
    "    for fv in set:\n",
    "        if len(fv) > max:\n",
    "            max = len(fv)\n",
    "    return max\n",
    "\n",
    "\n",
    "def padding_vecs(set, max):\n",
    "    padded_vectors = []\n",
    "    for fv in set:\n",
    "        padded_vec = [0] * max\n",
    "        padded_vec[:len(fv)] = fv\n",
    "        padded_vectors.append(padded_vec)\n",
    "    return padded_vectors\n",
    "\n",
    "\n",
    "def get_features_and_labels(data):\n",
    "    features = np.array(get_features(data))\n",
    "    labels = np.array(get_labels(data))\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create feature sets which simplifies handling the Word2Vec model's features. The final training and test data include the following scheme:\n",
    "\n",
    "[ [ sentences ], [ features for sentences ], [ label ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [[sentence[0], [wv[word] for word in sentence[0] if word in wv], sentence[1]] for sentence in train_set]\n",
    "test_data = [[sentence[0], [wv[word] for word in sentence[0] if word in wv], sentence[1]] for sentence in test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better handle the subdata, we split the big sets into the features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/s1tp6mzx73q2h3brm9fwyf0w0000gn/T/ipykernel_2376/1678109675.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  features = np.array(get_features(data))\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = get_features_and_labels(train_data)\n",
    "test_features, test_labels = get_features_and_labels(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do some preparation for the sets. Like adding zeros to make all vectors the same length according to the longest feature vector in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/s1tp6mzx73q2h3brm9fwyf0w0000gn/T/ipykernel_2376/3603363423.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  flat_train_features = np.array([np.array(sentence).flatten()\n",
      "/var/folders/m9/s1tp6mzx73q2h3brm9fwyf0w0000gn/T/ipykernel_2376/3603363423.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  flat_test_features = np.array([np.array(sentence).flatten()\n"
     ]
    }
   ],
   "source": [
    "flat_train_features = np.array([np.array(sentence).flatten()\n",
    "                         for sentence in train_features])\n",
    "max_train = get_featurelength(flat_train_features)\n",
    "flat_test_features = np.array([np.array(sentence).flatten()\n",
    "                         for sentence in test_features])\n",
    "max_test = get_featurelength(flat_test_features)\n",
    "max = (max_train if max_train > max_test else max_test)\n",
    "\n",
    "flat_train_features = padding_vecs(flat_train_features, max)\n",
    "train_features = flat_train_features\n",
    "flat_test_features = padding_vecs(flat_test_features, max)\n",
    "test_features = flat_test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Selection\n",
    "\n",
    "We used a grid search method to find the best values for the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.005, gamma=0.001, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "svm_model = sklearn.svm.SVC()\n",
    "\n",
    "param_grid = {'C': [0.001, 0.005, 0.01, 0.02, 0.05],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10],\n",
    "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "grid_search = GridSearchCV(svm_model, param_grid=param_grid)\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the final parameters we used for out best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_c = 0.01\n",
    "model_gamma = 0.001\n",
    "model_kernel = 'linear'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation\n",
    "\n",
    "In this cell, the model gets created. We simply provide the training features and labels and run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.01, gamma=1e-05, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.01, gamma=1e-05, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.01, gamma=1e-05, kernel='linear')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelName = \"../Models/SVM/cmpace_svm_{time}\".format(time=time)\n",
    "\n",
    "svm_model = sklearn.svm.SVC(C=model_c, gamma=model_gamma, kernel=model_kernel)\n",
    "svm_model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "A short evaluation of the final model's scores:\n",
    "\n",
    "**Accuracy**: is the percentage of data points that are classified correctly\\\n",
    "**Precision**: is the percentage of data points that are classified as positive that are actually positive\\\n",
    "**Recall**: is the percentage of positive data points that are classified as positive\\\n",
    "**F1 Score**: is a measure of both precision and recall. It is calculated as the harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters and Results for SVM Model ../Models/Word2Vec/cmpace_w2v_v2.1_PRIME.model\n",
      "C: 0.01\n",
      "gamma: 0.001\n",
      "Kernel: linear\n",
      "\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 score: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = svm_model.predict(test_features)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions)\n",
    "recall = recall_score(test_labels, predictions)\n",
    "f1 = f1_score(test_labels, predictions)\n",
    "\n",
    "result_string = f\"\"\"\n",
    "Parameters and Results for SVM Model {modelName}\n",
    "C: {model_c}\n",
    "gamma: {model_gamma}\n",
    "Kernel: {model_kernel}\n",
    "\n",
    "Accuracy: {accuracy}\n",
    "Precision: {precision}\n",
    "Recall: {recall}\n",
    "F1 score: {f1}\n",
    "\"\"\"\n",
    "\n",
    "print(result_string)\n",
    "logging(result_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we save our model to reuse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/SVM/cmpace_svm_2023-08-25_12:06:49.sav']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_model, f'{modelName}.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Example on how to use the classifier with an input sentence. The first example should produce 'True' and the second should bring 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = {\n",
    "  \"posts\": {\n",
    "    \"true\": {\n",
    "      \"post1\": \"I'm getting a `ConfigurationErrorsException` when I try to start my application. The error message says: `System.Configuration.ConfigurationErrorsException: The configuration file could not be loaded because of an error. The configuration file is located at `C:\\myApp\\app.config`. I've checked the file and it looks fine. I've also tried restarting my computer, but the problem persists. Any ideas what could be causing this?\",\n",
    "      \"post2\": \"I'm trying to connect to a database, but I'm getting an error about a missing configuration setting. The error message says: `Could not find a connection string named 'myConnectionString'. The connection string is defined in the configuration file, but it's not being found. I've checked the spelling of the connection string and it's correct. I'm not sure why it's not being found. Any ideas what I can do to fix this?\",\n",
    "      \"post3\": \"I'm trying to deploy my application to a new server, but I'm getting an error about a missing configuration file. The error message says: `Could not find the configuration file 'myApp.config'. I've made sure to copy the configuration file to the new server, but it's still not being found. I'm not sure why this is happening. Any ideas what I can do to fix this?\",\n",
    "      \"post4\": \"I'm trying to change a configuration setting, but I'm not sure how to do it. The configuration setting I want to change is the `port` for the database connection. I've looked in the documentation, but I can't find any information on how to change this setting. I'm not sure if I need to modify the configuration file or if there's another way to do it. Any ideas how I can do this?\",\n",
    "      \"post5\": \"I'm trying to debug a configuration error, but I'm not sure where to start. I've tried looking at the stack trace, but I can't make sense of it. I'm not sure what the different lines in the stack trace mean. Any ideas what I can do to debug this error?\"\n",
    "    },\n",
    "    \"false\": {\n",
    "      \"post1\": \"I'm trying to get my application to work, but I'm not sure what I'm doing wrong. I've tried everything I can think of, but I'm still getting errors. I'm not sure if the problem is with my code or with the configuration. Can anyone help me figure out what's going on?\",\n",
    "      \"post2\": \"I'm getting an error when I try to run my application. The error message says: `An unexpected error has occurred.` I'm not sure what this error means. I've tried looking in the documentation, but I can't find any information on it. Can anyone help me figure out what this error means?\",\n",
    "      \"post3\": \"I'm trying to deploy my application to a new server, but I'm having some problems. I'm getting an error message that says: `The deployment failed.` I'm not sure what's causing this error. I've tried everything I can think of, but I can't seem to fix it. Can anyone help me figure out what's causing this error?\",\n",
    "      \"post4\": \"I'm trying to debug my application, but I'm stuck. I've been following a tutorial, but I'm not sure what to do next. I'm not sure if I'm doing something wrong or if the tutorial is wrong. Can anyone help me figure out what I should do next?\",\n",
    "      \"post5\": \"I'm having some problems with my application. I'm not sure what's causing them. I've tried everything I can think of, but I can't seem to fix them. Can anyone help me figure out what's causing these problems?\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true': {'post1': \"I'm getting a `ConfigurationErrorsException` when I try to start my application. The error message says: `System.Configuration.ConfigurationErrorsException: The configuration file could not be loaded because of an error. The configuration file is located at `C:\\\\myApp\\x07pp.config`. I've checked the file and it looks fine. I've also tried restarting my computer, but the problem persists. Any ideas what could be causing this?\", 'post2': \"I'm trying to connect to a database, but I'm getting an error about a missing configuration setting. The error message says: `Could not find a connection string named 'myConnectionString'. The connection string is defined in the configuration file, but it's not being found. I've checked the spelling of the connection string and it's correct. I'm not sure why it's not being found. Any ideas what I can do to fix this?\", 'post3': \"I'm trying to deploy my application to a new server, but I'm getting an error about a missing configuration file. The error message says: `Could not find the configuration file 'myApp.config'. I've made sure to copy the configuration file to the new server, but it's still not being found. I'm not sure why this is happening. Any ideas what I can do to fix this?\", 'post4': \"I'm trying to change a configuration setting, but I'm not sure how to do it. The configuration setting I want to change is the `port` for the database connection. I've looked in the documentation, but I can't find any information on how to change this setting. I'm not sure if I need to modify the configuration file or if there's another way to do it. Any ideas how I can do this?\", 'post5': \"I'm trying to debug a configuration error, but I'm not sure where to start. I've tried looking at the stack trace, but I can't make sense of it. I'm not sure what the different lines in the stack trace mean. Any ideas what I can do to debug this error?\"}, 'false': {'post1': \"I'm trying to get my application to work, but I'm not sure what I'm doing wrong. I've tried everything I can think of, but I'm still getting errors. I'm not sure if the problem is with my code or with the configuration. Can anyone help me figure out what's going on?\", 'post2': \"I'm getting an error when I try to run my application. The error message says: `An unexpected error has occurred.` I'm not sure what this error means. I've tried looking in the documentation, but I can't find any information on it. Can anyone help me figure out what this error means?\", 'post3': \"I'm trying to deploy my application to a new server, but I'm having some problems. I'm getting an error message that says: `The deployment failed.` I'm not sure what's causing this error. I've tried everything I can think of, but I can't seem to fix it. Can anyone help me figure out what's causing this error?\", 'post4': \"I'm trying to debug my application, but I'm stuck. I've been following a tutorial, but I'm not sure what to do next. I'm not sure if I'm doing something wrong or if the tutorial is wrong. Can anyone help me figure out what I should do next?\", 'post5': \"I'm having some problems with my application. I'm not sure what's causing them. I've tried everything I can think of, but I can't seem to fix them. Can anyone help me figure out what's causing these problems?\"}}\n",
      "SVC(C=0.01, gamma=0.001, kernel='linear')\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "post = \"I'm getting a ConfigurationErrorsException when I try to open a form in design view in Visual Studio 2019. The error message says: System.Configuration.ConfigurationErrorsException: The configuration file could not be loaded because of an error. I've checked the configuration file and it looks fine. I've also tried restarting Visual Studio, but the problem persists. Any ideas what could be causing this? Thanks!\"\n",
    "# post = \"Hi everyone, I'm working on a project and I'm trying to make my code more efficient. I've been reading some articles on the topic, but I'm still not sure what the best approach is. Can anyone give me some tips on how to make my code more efficient? Thanks!\"\n",
    "\n",
    "word2vec_model = gensim.models.Word2Vec.load(\n",
    "    \"../Models/Word2Vec/cmpace_w2v_v2.1_PRIME.model\")\n",
    "wv = word2vec_model.wv\n",
    "\n",
    "sentences = [[post,None]]\n",
    "sentences[0][0] = preprocess_string(sentences[0][0], CUSTOM_FILTERS)\n",
    "\n",
    "input = [[sentence[0], [wv[word] for word in sentence[0] if word in wv], None] for sentence in sentences]\n",
    "features, labels = get_features_and_labels(input)\n",
    "features = np.array([np.array(sentence).flatten()\n",
    "                         for sentence in features])\n",
    "features = padding_vecs(features, 118600)\n",
    "\n",
    "\n",
    "svm_model = joblib.load(\"../Models/SVM/cmpace_svm_v2.4_PRIME.sav\")\n",
    "print(svm_model)\n",
    "label = svm_model.predict(features)\n",
    "print(label[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
